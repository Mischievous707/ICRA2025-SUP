# CTSG: Context and Topology based Multi-Modal Scene Graph for Visual Target Navigation
This repository is the official implementation of the paper: CTSG: Context and Topology based Multi-Modal Scene Graph for Visual Target Navigation[ğŸ”—](http://)

<img src="/img/intruduction.png" alt="github-pic"  />

> - [ ] **[L]** CTSG is a hierarchical 3D scene graph mapping method designed for visual object navigation. It features a dual-layer structure: an object layer and a novel *Conway* layer (short for *context* and *way* topology), composed of topological waypoints enriched with multi-modal context information.
>
> https://github.com/user-attachments/assets/ff1d11a1-2961-4fb1-8d08-ae9c999f9cda
>
<!--
## Abstract
For visual target navigation tasks, a suitable environment representation plays a vital part in robot system to complete the navigation tasks. 3D Scene Graphs serve as sparse representations that excel at representing environments efficiently compare to dense semantic maps. Typical Scene Graphs are generally constructed based on multi-level semantic labels with hierarchical structures, which may lead to the loss of valuable spatial information, such as spatial topological relations, common sense understanding and visual context information. In this work, we propose **CTSG**, a Hierarchical 3D scene graph mapping approach for visual object navigation. Our graph adopts a dual-layer structure. Besides object layer, a novel conway (short for context information and way topology) layer is introduced, which consists of topological waypoints with rich multi-modal context information. We demonstrate the effectiveness of our method in novel visual target navigation tasks through simulation and real-world experiments across varied environments and instructions.

## Video

https://github.com/user-attachments/assets/637966af-dfbb-458e-bb6a-15ddcbc1a3d8


## Approach

<img src="/img/pipeline.png" />

> æè¿°-ä¼˜åŠ¿

### Scene Graph Construction

<img src="/img/conwaygraph.png" />

> æè¿°---æ¢æˆgif

<img src="/img/semantic.png" />

> æè¿°

### Visual Target Navigation with Scene Graph

> **[M]**æ•´ä½“æ¶æ„å›¾+retrieval detailsæè¿°
-->

## Experiment

[parameter_list](#section-heading)

### 1. Dataset

1. scene data

   HM3D

   ï¼ˆMatterport 3Dï¼‰

2. task data

   HM3D

### 2. Scene Graph 

obj location acc: å¯¹æ¯”ConceptGraphï¼Œhovsg?åœ¨gtç¯å¢ƒä¸‹è¯„æµ‹ 

1. gtä»habitat-simå¦‚ä½•è·å–
2. å¦‚ä½•å¯¹æ¯”ï¼ˆå’Œcompetetiveçš„xxæ–¹æ³•å¯¹æ¯”ï¼‰
3. ç»“æœï¼š

| dataset | scene | ConceptGraph | ours |
| ----------- | ----- | ------------ | ---- |
|      _       |       |              |      |
|       _      |       |              |      |

åˆ†æï¼š

æè¿°ï¼šä¸ºä»€ä¹ˆåšï¼Œæ€ä¹ˆåšï¼Œç»“æœå¦‚ä½•ï¼Œä»£è¡¨xx

### 3. Visual Target Navigation

1. Navigation Evaluation

   conwayæ•´ä½“æ–¹æ³•ï¼ˆåŒ…æ‹¬æ„å›¾ã€æ£€ç´¢ï¼‰æœ‰æ•ˆæ€§

   â€‹	1. with/withoutï¼šåœ¨åŸæœ¬çš„åŸºç¡€ä¸Šå»æ‰conwayæ£€ç´¢=åªå¯¹æ‰€æœ‰objectåˆ—è¡¨åšclip+vlm

   > 2. room clusterï¼šåœ¨åŸæœ¬çš„åŸºç¡€ä¸ŠæŠŠconwayæ¢æˆroomï¼ˆèšç±»å¾—åˆ°ï¼Œæœ‰å›¾æ–‡ï¼‰ï¼Œå…¶ä»–ä¸å˜
   
   | scene / SR  |     IEVE  | Object Only | Ours    |
   |:-------------:|:-------------:|:-------------:|:---------:|
   | Dd4bFSTQ8gi | 33.6      | 24.00       | 41.33   |
   | QaLdnwvtxbs | 66.4       | 48.15       | 44.44   |
   | VBzV5z6i1WS | 44.8       | 34.38       | 48.96   |
   | ziup5kvtCCR | 45.6       | 43.59       | 33.33   |
   | Nfvxx8J5NCo | 35.2       | 25.64       | 41.03   |
   | svBbv1Pavdk | 57.6       | 17.54       | 47.37   |
   | BAbdmeyTvMZ | 60.8       | 39.40       | 42.42   |
   | mv2HUxq3B53 | 37.6       | 40.00       | 22.67   |
   | mean       | 47.9       | 34.09      | 40.19   |


   <!--å®éªŒè®¾ç½®ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŸºçº¿æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç›´æ¥åœ¨åœºæ™¯ä¸­æ‰€æœ‰æ£€æµ‹åˆ°çš„ç‰©ä½“å®ä¾‹åˆ—è¡¨ä¸­æœç´¢ç›®æ ‡å®ä¾‹, æ‰¾åˆ°ç›®æ ‡å®ä¾‹åï¼Œåˆ©ç”¨å¯¼èˆªå›¾è§„åˆ’è·¯å¾„å®Œæˆä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™ç§æ‰å¹³åŒ–çš„æ£€ç´¢æ–¹æ³•ä»…å…³æ³¨ç‰©ä½“æœ¬èº«è€Œå¿½ç•¥äº†å…¶å‘¨å›´ç¯å¢ƒçš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ—¶ï¼Œå®ƒåªèƒ½åœ¨è¾ƒè¿œçš„è·ç¦»ä¸Šæ‰èƒ½å‡†ç¡®åœ°è¯†åˆ«å‡ºç›®æ ‡ç‰©ä½“ï¼Œå¯¼è‡´äº†å¯¼èˆªæˆåŠŸç‡çš„ä¸‹é™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è‡ªå·±çš„å¯¼èˆªç»“æœä¸å…¬å¼€å¯ç”¨çš„æœ€å…ˆè¿›æ–¹æ³•IEVEåœ¨æˆ‘ä»¬çš„è¯„ä¼°æ•°æ®é›†ä¸Šè¿›è¡Œäº†æ¯”è¾ƒï¼Œå°½ç®¡IEVEç®—æ³•åœ¨å¯¼èˆªæ€§èƒ½ä¸Šç•¥èƒœä¸€ç­¹ï¼Œä½†å…¶ä¾èµ–äºè®­ç»ƒè¿‡ç¨‹ä»¥ä¼˜åŒ–æ¨¡å‹å‚æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ— éœ€è®­ç»ƒçš„ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡ç›´æ¥åº”ç”¨æ¨¡å‹äºæ–°åœºæ™¯æ¥è¯„ä¼°å…¶æ³›åŒ–èƒ½åŠ›ï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚-->
   Initially, we constructed a baseline model that directly searches for the target instance within the list of all detected object instances in the scene. Once the target instance is identified, a navigation graph is utilized to plan a path and complete the task. However, this flattened retrieval method, which focuses solely on the object itself and neglects the contextual information of its surrounding environment, can only accurately recognize the target object at a greater distance, leading to a decrease in navigation success rates. Furthermore, we compared our navigation results with the publicly available state-of-the-art method, IEVE, on our evaluation dataset. Although the IEVE algorithm slightly outperforms ours in navigation performance, it relies on a training process to optimize model parameters. In contrast, our method employs a training-free strategy, aiming to assess its generalization capability by directly applying the model to new scenes, thereby providing a more flexible solution in practical applications.

2. Retrieval Evaluation

   å»æ‰VLMä¸ç¡®å®šå› ç´ 

   1. Top K Accuracy

      ä¸ºäº†æ‰¾åˆ°æœ€å¥½çš„K

      å»æ‰VLMä¸ç¡®å®šå› ç´ ï¼Œæ¢è®¨clipç»“æœçš„precision

      é€‰å‡ºæœ€åˆé€‚çš„K

      ğŸ‘‡

      | layer/Top K acc | K=1  | K=3  | K=5  |
      | --------------- | ---- | ---- | ---- |
      | conway          |      |      |      |
      | object          |      |      |      |

      > æˆ–è€…
      >
      > åŠ ä¸Švlmï¼Œè¯„æµ‹ä¸¤ä¸ªå†…å®¹ï¼š1. clipé€‰æ‹©çš„ç»“æœï¼Œ2. VLMå¯¹ä¸åŒKçš„è¡¨ç°

   2. conway  & roomï¼Ÿå¤šæ¨¡æ€orå•æ¨¡æ€ï¼Ÿåœ¨ç¡®å®štopkè¶…å‚ä¹‹åè¿›è¡Œ
      
      å•æ¨¡æ€å¤šæ¨¡æ€

      1. å»æ‰vlmçš„æˆ‘ä»¬çš„æ–¹æ³•ï¼Œçº¯è¯„ä¼°graphï¼š

         clip conway top 3 --> expand to 9 --> clip obj top 1

      2.å»æ‰æ–‡æœ¬æ¨¡æ€ï¼š

         clip conway top 3 --> expand to 9 --> clip objï¼ˆonly imageï¼‰ top 1

      3. å»æ‰å›¾åƒæ¨¡æ€ï¼š

         clip conway top 3 --> expand to 9 --> clip objï¼ˆonly textï¼‰ top 1
      
      
      5. conway æ¢æˆgt room

         clip room label top 3 --> clip obj top 1

      6. å»æ‰å›¾åƒæ¨¡æ€ï¼ˆè®ºæ–‡baselineï¼‰

         clip room label top 3 --> clip objï¼ˆonly textï¼‰ top 1
3. å¤šä»»åŠ¡task

      


## å‚æ•°è¡¨<a name="section-heading"></a>

| Subsystem | Hyperparameters | Value |
| --------- | --------------- | ----- |
|     _      |                 |       |
|    _       |                 |       |
|       _    |                 |       |

## Case Video
### simulator



https://github.com/user-attachments/assets/20362768-7054-4c69-925a-1913e1fb4b35



### real world






